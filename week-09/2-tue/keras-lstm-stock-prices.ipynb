{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('data/NSE-TATAGLOBAL.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n0  2018-09-28  234.05  235.95  230.20  233.50  233.75               3069914   \n1  2018-09-27  234.55  236.80  231.10  233.80  233.25               5082859   \n2  2018-09-26  240.00  240.00  232.50  235.00  234.25               2240909   \n3  2018-09-25  233.30  236.75  232.00  236.25  236.10               2349368   \n4  2018-09-24  233.55  239.20  230.75  234.00  233.30               3423509   \n\n   Turnover (Lacs)  \n0          7162.35  \n1         11859.95  \n2          5248.60  \n3          5503.90  \n4          7999.55  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Last</th>\n      <th>Close</th>\n      <th>Total Trade Quantity</th>\n      <th>Turnover (Lacs)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-28</td>\n      <td>234.05</td>\n      <td>235.95</td>\n      <td>230.20</td>\n      <td>233.50</td>\n      <td>233.75</td>\n      <td>3069914</td>\n      <td>7162.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-27</td>\n      <td>234.55</td>\n      <td>236.80</td>\n      <td>231.10</td>\n      <td>233.80</td>\n      <td>233.25</td>\n      <td>5082859</td>\n      <td>11859.95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-26</td>\n      <td>240.00</td>\n      <td>240.00</td>\n      <td>232.50</td>\n      <td>235.00</td>\n      <td>234.25</td>\n      <td>2240909</td>\n      <td>5248.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-25</td>\n      <td>233.30</td>\n      <td>236.75</td>\n      <td>232.00</td>\n      <td>236.25</td>\n      <td>236.10</td>\n      <td>2349368</td>\n      <td>5503.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-24</td>\n      <td>233.55</td>\n      <td>239.20</td>\n      <td>230.75</td>\n      <td>234.00</td>\n      <td>233.30</td>\n      <td>3423509</td>\n      <td>7999.55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# creating data with timesteps\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 2035):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for initializing the neural net\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# for adding a densely connected network layer\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Softmax\n",
    "\n",
    "# for adding the Long Short-Term Memory layer\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# for adding dropout layers that prevent overfitting\n",
    "from keras.layers import Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding the first LSTM layer and some dropout regularization\n",
    "regressor.add(LSTM(units = 50, return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "regressor.fit(X_train,y_train, epochs = 100, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset_test = pd.read_csv('data/tatatest.csv')\n",
    "# real_stock_price = dataset_test.iloc[:, 1:2].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TO predict future prices, we must do a couple things:\n",
    "    1. Merge the training and test set on the 0 axis\n",
    "    2. Set time step to 60.\n",
    "    3. Use MinMaxScaler to transform the new data\n",
    "    4. Reshape the dataset as done previously"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Getting the predicted stock price of 2017\n",
    "# dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "# inputs = inputs.reshape(-1,1)\n",
    "# inputs = sc.transform(inputs)\n",
    "# X_test = []\n",
    "# for i in range(60, 76):\n",
    "#     X_test.append(inputs[i-60:i, 0])\n",
    "# X_test = np.array(X_test)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# predicted_stock_price = regressor.predict(X_test)\n",
    "# predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.plot(real_stock_price, color = 'black', label = 'TATA Stock Price')\n",
    "# plt.plot(predicted_stock_price, color = 'green', label = 'Predicted TATA Stock Price')\n",
    "# plt.title('TATA Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('TATA Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('data/tatatest.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i - 60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color='red', label='Real TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted TAT Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('data/tatatest.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i - 60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color='red', label='Real TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted TAT Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('data/tatatest.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i - 60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color='red', label='Real TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted TAT Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m X_test \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(X_test, (X_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], X_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     14\u001B[0m predicted_stock_price \u001B[38;5;241m=\u001B[39m regressor\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m---> 15\u001B[0m predicted_stock_price \u001B[38;5;241m=\u001B[39m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minverse_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredicted_stock_price\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Visualising the results\u001B[39;00m\n\u001B[0;32m     18\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(real_stock_price, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mred\u001B[39m\u001B[38;5;124m'\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReal TATA Stock Price\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:525\u001B[0m, in \u001B[0;36mMinMaxScaler.inverse_transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;124;03m\"\"\"Undo the scaling of X according to feature_range.\u001B[39;00m\n\u001B[0;32m    512\u001B[0m \n\u001B[0;32m    513\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;124;03m    Transformed data.\u001B[39;00m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    523\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 525\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    529\u001B[0m X \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_\n\u001B[0;32m    530\u001B[0m X \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\sklearn\\utils\\validation.py:794\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    790\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to convert array of bytes/strings \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    791\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minto decimal numbers with dtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    792\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m--> 794\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    795\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    796\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    797\u001B[0m     )\n\u001B[0;32m    799\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m    800\u001B[0m     _assert_all_finite(array, allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv('data/tatatest.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i - 60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color='red', label='Real TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted TAT Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lighthouseenv",
   "language": "python",
   "display_name": "LighthouseEnv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}