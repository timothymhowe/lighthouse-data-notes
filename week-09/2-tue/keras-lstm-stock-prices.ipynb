{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('data/NSE-TATAGLOBAL.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n0  2018-09-28  234.05  235.95  230.20  233.50  233.75               3069914   \n1  2018-09-27  234.55  236.80  231.10  233.80  233.25               5082859   \n2  2018-09-26  240.00  240.00  232.50  235.00  234.25               2240909   \n3  2018-09-25  233.30  236.75  232.00  236.25  236.10               2349368   \n4  2018-09-24  233.55  239.20  230.75  234.00  233.30               3423509   \n\n   Turnover (Lacs)  \n0          7162.35  \n1         11859.95  \n2          5248.60  \n3          5503.90  \n4          7999.55  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Last</th>\n      <th>Close</th>\n      <th>Total Trade Quantity</th>\n      <th>Turnover (Lacs)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-28</td>\n      <td>234.05</td>\n      <td>235.95</td>\n      <td>230.20</td>\n      <td>233.50</td>\n      <td>233.75</td>\n      <td>3069914</td>\n      <td>7162.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-27</td>\n      <td>234.55</td>\n      <td>236.80</td>\n      <td>231.10</td>\n      <td>233.80</td>\n      <td>233.25</td>\n      <td>5082859</td>\n      <td>11859.95</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-26</td>\n      <td>240.00</td>\n      <td>240.00</td>\n      <td>232.50</td>\n      <td>235.00</td>\n      <td>234.25</td>\n      <td>2240909</td>\n      <td>5248.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-25</td>\n      <td>233.30</td>\n      <td>236.75</td>\n      <td>232.00</td>\n      <td>236.25</td>\n      <td>236.10</td>\n      <td>2349368</td>\n      <td>5503.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-24</td>\n      <td>233.55</td>\n      <td>239.20</td>\n      <td>230.75</td>\n      <td>234.00</td>\n      <td>233.30</td>\n      <td>3423509</td>\n      <td>7999.55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# creating data with timesteps\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 2035):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# for initializing the neural net\n",
    "from keras.models import Sequential\n",
    "\n",
    "# for adding a densely connected network layer\n",
    "from keras.layers import Dense\n",
    "\n",
    "# for adding the Long Short-Term Memory layer\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# for adding dropout layers that prevent overfitting\n",
    "from keras.layers import Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 8s 45ms/step - loss: 0.0418\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0370\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0368\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0366\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0365\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.0363\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 0.0363\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0361\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0362\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0361\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0361\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0361\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0360\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0363\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0361\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0359\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0360\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0359\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0361\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.0360\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0359\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0358\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0359\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0359\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0359\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0359\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0358\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0359\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0359\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0359\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0359\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0358\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0357\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0359\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0359\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0356\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0358\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0357\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 3s 46ms/step - loss: 0.0358\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0358\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0359\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0358\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.0358\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0358\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 3s 47ms/step - loss: 0.0357\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0358\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 3s 48ms/step - loss: 0.0357\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 0.0357\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27479468940>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences=True,input_shape=(X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "regressor.fit(X_train,y_train, epochs = 100, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('data/tata-test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TO predict future prices, we must do a couple things:\n",
    "    1. Merge the training and test set on the 0 axis\n",
    "    2. Set time step to 60.\n",
    "    3. Use MinMaxScaler to transform the new data\n",
    "    4. Reshape the dataset as done previously"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "\n",
    "mf = lambda xs: [sc.inverse_transform(x) for x in xs]\n",
    "predicted_stock_price = mf(predicted_stock_price)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[147.52725],\n        [145.03494],\n        [145.13113],\n        [144.90611],\n        [144.77371],\n        [144.65465],\n        [144.54552],\n        [144.45935],\n        [144.3739 ],\n        [144.31807],\n        [144.29027],\n        [144.28694],\n        [144.30478],\n        [144.30011],\n        [144.27725],\n        [144.2663 ],\n        [144.27246],\n        [144.2647 ],\n        [144.25873],\n        [144.26376],\n        [144.27687],\n        [144.29941],\n        [144.33766],\n        [144.36372],\n        [144.38354],\n        [144.36426],\n        [144.33478],\n        [144.30289],\n        [144.29185],\n        [144.26761],\n        [144.20982],\n        [144.17305],\n        [144.15057],\n        [144.13132],\n        [144.10036],\n        [144.0944 ],\n        [144.0591 ],\n        [144.01085],\n        [143.95444],\n        [143.91103],\n        [143.89511],\n        [143.9224 ],\n        [143.93277],\n        [143.93504],\n        [143.94017],\n        [143.93735],\n        [143.92616],\n        [143.93245],\n        [143.96404],\n        [144.00603],\n        [144.03906],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ]], dtype=float32),\n array([[147.54872],\n        [145.05501],\n        [145.1492 ],\n        [144.88156],\n        [144.72876],\n        [144.59052],\n        [144.48753],\n        [144.39151],\n        [144.32913],\n        [144.29733],\n        [144.29147],\n        [144.30771],\n        [144.302  ],\n        [144.27844],\n        [144.26703],\n        [144.27287],\n        [144.26488],\n        [144.25877],\n        [144.26369],\n        [144.27675],\n        [144.29924],\n        [144.33748],\n        [144.36354],\n        [144.38339],\n        [144.3641 ],\n        [144.33466],\n        [144.30276],\n        [144.29176],\n        [144.26753],\n        [144.20978],\n        [144.173  ],\n        [144.15053],\n        [144.1313 ],\n        [144.10034],\n        [144.09439],\n        [144.05908],\n        [144.01083],\n        [143.95444],\n        [143.91103],\n        [143.89511],\n        [143.9224 ],\n        [143.93277],\n        [143.93504],\n        [143.94017],\n        [143.93735],\n        [143.92616],\n        [143.93245],\n        [143.96404],\n        [144.00603],\n        [144.03906],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ],\n        [144.98286]], dtype=float32),\n array([[147.54872],\n        [145.057  ],\n        [145.11366],\n        [144.8297 ],\n        [144.66049],\n        [144.53018],\n        [144.41838],\n        [144.34604],\n        [144.30801],\n        [144.29828],\n        [144.31206],\n        [144.30478],\n        [144.2802 ],\n        [144.2681 ],\n        [144.27347],\n        [144.26517],\n        [144.25887],\n        [144.26364],\n        [144.27663],\n        [144.29906],\n        [144.3373 ],\n        [144.36334],\n        [144.3832 ],\n        [144.36392],\n        [144.33449],\n        [144.30264],\n        [144.29164],\n        [144.26744],\n        [144.20969],\n        [144.17294],\n        [144.1505 ],\n        [144.13126],\n        [144.10031],\n        [144.09436],\n        [144.05907],\n        [144.01083],\n        [143.95442],\n        [143.91101],\n        [143.8951 ],\n        [143.92238],\n        [143.93277],\n        [143.93504],\n        [143.94017],\n        [143.93735],\n        [143.92616],\n        [143.93245],\n        [143.96404],\n        [144.00603],\n        [144.03908],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818]], dtype=float32),\n array([[147.5508 ],\n        [145.02165],\n        [145.06178],\n        [144.76149],\n        [144.60017],\n        [144.46107],\n        [144.37294],\n        [144.32492],\n        [144.30898],\n        [144.31886],\n        [144.30913],\n        [144.28297],\n        [144.26985],\n        [144.27455],\n        [144.2658 ],\n        [144.25916],\n        [144.26373],\n        [144.27658],\n        [144.29893],\n        [144.33711],\n        [144.36314],\n        [144.383  ],\n        [144.36372],\n        [144.3343 ],\n        [144.30247],\n        [144.2915 ],\n        [144.26733],\n        [144.2096 ],\n        [144.17287],\n        [144.15044],\n        [144.13121],\n        [144.10027],\n        [144.09433],\n        [144.05904],\n        [144.01082],\n        [143.9544 ],\n        [143.91101],\n        [143.8951 ],\n        [143.92238],\n        [143.93277],\n        [143.93504],\n        [143.94017],\n        [143.93735],\n        [143.92616],\n        [143.93245],\n        [143.96404],\n        [144.00603],\n        [144.03908],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.46819]], dtype=float32),\n array([[147.51237],\n        [144.96895],\n        [144.99245],\n        [144.70059],\n        [144.5307 ],\n        [144.41542],\n        [144.3517 ],\n        [144.3258 ],\n        [144.32951],\n        [144.3159 ],\n        [144.28731],\n        [144.27263],\n        [144.27628],\n        [144.26685],\n        [144.25977],\n        [144.26402],\n        [144.27664],\n        [144.29889],\n        [144.33698],\n        [144.36296],\n        [144.3828 ],\n        [144.36353],\n        [144.33412],\n        [144.30229],\n        [144.29135],\n        [144.26718],\n        [144.20947],\n        [144.17278],\n        [144.15034],\n        [144.13115],\n        [144.10022],\n        [144.0943 ],\n        [144.059  ],\n        [144.0108 ],\n        [143.95439],\n        [143.911  ],\n        [143.89508],\n        [143.92238],\n        [143.93277],\n        [143.93504],\n        [143.94016],\n        [143.93733],\n        [143.92616],\n        [143.93245],\n        [143.96404],\n        [144.00603],\n        [144.03908],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.46819],\n        [146.96971]], dtype=float32),\n array([[147.49504],\n        [144.92871],\n        [144.95113],\n        [144.64363],\n        [144.49246],\n        [144.39836],\n        [144.35487],\n        [144.34756],\n        [144.32724],\n        [144.29453],\n        [144.27727],\n        [144.27933],\n        [144.26884],\n        [144.26105],\n        [144.26485],\n        [144.27713],\n        [144.29913],\n        [144.33707],\n        [144.36295],\n        [144.3827 ],\n        [144.36339],\n        [144.33395],\n        [144.30214],\n        [144.2912 ],\n        [144.26704],\n        [144.20935],\n        [144.17265],\n        [144.15025],\n        [144.13106],\n        [144.10014],\n        [144.09424],\n        [144.05896],\n        [144.01076],\n        [143.95438],\n        [143.91096],\n        [143.89507],\n        [143.92236],\n        [143.93275],\n        [143.93503],\n        [143.94016],\n        [143.93733],\n        [143.92616],\n        [143.93245],\n        [143.96404],\n        [144.00603],\n        [144.03908],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.46819],\n        [146.96971],\n        [147.3635 ]], dtype=float32),\n array([[147.47029],\n        [144.90079],\n        [144.90298],\n        [144.61107],\n        [144.47878],\n        [144.40343],\n        [144.37764],\n        [144.34586],\n        [144.30617],\n        [144.28467],\n        [144.28413],\n        [144.272  ],\n        [144.26317],\n        [144.26624],\n        [144.27806],\n        [144.29971],\n        [144.3374 ],\n        [144.3631 ],\n        [144.38272],\n        [144.36334],\n        [144.33386],\n        [144.302  ],\n        [144.29105],\n        [144.2669 ],\n        [144.20921],\n        [144.17255],\n        [144.15015],\n        [144.13097],\n        [144.10008],\n        [144.09418],\n        [144.05891],\n        [144.01073],\n        [143.95435],\n        [143.91095],\n        [143.89505],\n        [143.92236],\n        [143.93274],\n        [143.93503],\n        [143.94016],\n        [143.93733],\n        [143.92616],\n        [143.93243],\n        [143.96404],\n        [144.00603],\n        [144.03908],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.46819],\n        [146.96971],\n        [147.3635 ],\n        [147.62656]], dtype=float32),\n array([[147.46535],\n        [144.87135],\n        [144.88304],\n        [144.6054 ],\n        [144.48857],\n        [144.42888],\n        [144.3774 ],\n        [144.32555],\n        [144.29675],\n        [144.29181],\n        [144.27702],\n        [144.26651],\n        [144.26852],\n        [144.27962],\n        [144.30077],\n        [144.33809],\n        [144.36353],\n        [144.38298],\n        [144.36345],\n        [144.33386],\n        [144.30194],\n        [144.29095],\n        [144.26678],\n        [144.20908],\n        [144.17241],\n        [144.15004],\n        [144.13087],\n        [144.09999],\n        [144.09409],\n        [144.05885],\n        [144.01067],\n        [143.9543 ],\n        [143.9109 ],\n        [143.89502],\n        [143.92233],\n        [143.93272],\n        [143.93501],\n        [143.94014],\n        [143.93732],\n        [143.92615],\n        [143.93243],\n        [143.96404],\n        [144.00603],\n        [144.03906],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.3635 ],\n        [147.62656],\n        [147.73491]], dtype=float32),\n array([[147.43979],\n        [144.85545],\n        [144.87984],\n        [144.6168 ],\n        [144.51497],\n        [144.42915],\n        [144.3574 ],\n        [144.3163 ],\n        [144.30397],\n        [144.28474],\n        [144.27156],\n        [144.2719 ],\n        [144.28192],\n        [144.30237],\n        [144.33919],\n        [144.36427],\n        [144.38344],\n        [144.36371],\n        [144.33398],\n        [144.30196],\n        [144.29091],\n        [144.26668],\n        [144.20897],\n        [144.17229],\n        [144.1499 ],\n        [144.13075],\n        [144.09987],\n        [144.09401],\n        [144.05878],\n        [144.01059],\n        [143.95424],\n        [143.91086],\n        [143.89497],\n        [143.9223 ],\n        [143.9327 ],\n        [143.935  ],\n        [143.94012],\n        [143.93732],\n        [143.92615],\n        [143.93243],\n        [143.96402],\n        [144.00603],\n        [144.03906],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.3635 ],\n        [147.62656],\n        [147.73491],\n        [147.75157]], dtype=float32),\n array([[147.44803],\n        [144.87117],\n        [144.9043 ],\n        [144.65143],\n        [144.52017],\n        [144.41197],\n        [144.34967],\n        [144.32433],\n        [144.29736],\n        [144.27957],\n        [144.27716],\n        [144.28549],\n        [144.30484],\n        [144.34094],\n        [144.3655 ],\n        [144.3843 ],\n        [144.36427],\n        [144.33434],\n        [144.30215],\n        [144.29099],\n        [144.26668],\n        [144.20891],\n        [144.17218],\n        [144.1498 ],\n        [144.13063],\n        [144.09976],\n        [144.0939 ],\n        [144.05867],\n        [144.01051],\n        [143.95418],\n        [143.9108 ],\n        [143.89493],\n        [143.92227],\n        [143.93266],\n        [143.93497],\n        [143.94011],\n        [143.9373 ],\n        [143.92613],\n        [143.93242],\n        [143.96402],\n        [144.00603],\n        [144.03906],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.3635 ],\n        [147.62657],\n        [147.73491],\n        [147.75159],\n        [147.64954]], dtype=float32),\n array([[147.45627],\n        [144.88928],\n        [144.93474],\n        [144.65398],\n        [144.50143],\n        [144.40335],\n        [144.35721],\n        [144.31746],\n        [144.29205],\n        [144.28508],\n        [144.29068],\n        [144.30835],\n        [144.34337],\n        [144.36719],\n        [144.38548],\n        [144.3651 ],\n        [144.33487],\n        [144.30249],\n        [144.29114],\n        [144.26674],\n        [144.2089 ],\n        [144.17213],\n        [144.1497 ],\n        [144.13052],\n        [144.09966],\n        [144.09378],\n        [144.05856],\n        [144.01042],\n        [143.95409],\n        [143.91075],\n        [143.89487],\n        [143.92221],\n        [143.93263],\n        [143.93494],\n        [143.94008],\n        [143.93727],\n        [143.92612],\n        [143.9324 ],\n        [143.964  ],\n        [144.00603],\n        [144.03906],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.3635 ],\n        [147.62657],\n        [147.73491],\n        [147.75159],\n        [147.64952],\n        [147.54375]], dtype=float32),\n array([[147.467  ],\n        [144.91333],\n        [144.93312],\n        [144.63257],\n        [144.49123],\n        [144.40999],\n        [144.34985],\n        [144.31187],\n        [144.29742],\n        [144.29851],\n        [144.31346],\n        [144.3468 ],\n        [144.36957],\n        [144.38713],\n        [144.36624],\n        [144.33565],\n        [144.30298],\n        [144.29144],\n        [144.26689],\n        [144.20892],\n        [144.17209],\n        [144.14961],\n        [144.13042],\n        [144.09953],\n        [144.09367],\n        [144.05846],\n        [144.01031],\n        [143.954  ],\n        [143.91066],\n        [143.8948 ],\n        [143.92216],\n        [143.93259],\n        [143.93489],\n        [143.94005],\n        [143.93726],\n        [143.9261 ],\n        [143.93239],\n        [143.964  ],\n        [144.00601],\n        [144.03905],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.3635 ],\n        [147.62657],\n        [147.73491],\n        [147.75159],\n        [147.64952],\n        [147.54375],\n        [147.46417]], dtype=float32),\n array([[147.48143],\n        [144.90358],\n        [144.90628],\n        [144.6189 ],\n        [144.49579],\n        [144.40147],\n        [144.34364],\n        [144.31691],\n        [144.31065],\n        [144.32117],\n        [144.35184],\n        [144.37292],\n        [144.38943],\n        [144.36781],\n        [144.33672],\n        [144.3037 ],\n        [144.29189],\n        [144.26714],\n        [144.20903],\n        [144.1721 ],\n        [144.14955],\n        [144.13031],\n        [144.09941],\n        [144.09355],\n        [144.05833],\n        [144.0102 ],\n        [143.9539 ],\n        [143.91057],\n        [143.89473],\n        [143.92209],\n        [143.93253],\n        [143.93484],\n        [143.94   ],\n        [143.93723],\n        [143.92607],\n        [143.93237],\n        [143.96399],\n        [144.00601],\n        [144.03905],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.36351],\n        [147.62657],\n        [147.73492],\n        [147.75159],\n        [147.64954],\n        [147.54375],\n        [147.46417],\n        [147.35143]], dtype=float32),\n array([[147.4575 ],\n        [144.86642],\n        [144.88516],\n        [144.61879],\n        [144.48447],\n        [144.39368],\n        [144.34781],\n        [144.32968],\n        [144.33307],\n        [144.35938],\n        [144.37784],\n        [144.39268],\n        [144.37001],\n        [144.33823],\n        [144.30469],\n        [144.29254],\n        [144.26752],\n        [144.20924],\n        [144.17216],\n        [144.14954],\n        [144.13023],\n        [144.09929],\n        [144.09341],\n        [144.0582 ],\n        [144.01006],\n        [143.95377],\n        [143.91045],\n        [143.89464],\n        [143.92201],\n        [143.93245],\n        [143.93478],\n        [143.93997],\n        [143.93718],\n        [143.92604],\n        [143.93237],\n        [143.96399],\n        [144.006  ],\n        [144.03903],\n        [144.05406],\n        [144.05446],\n        [144.01852],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.36351],\n        [147.62657],\n        [147.73491],\n        [147.75159],\n        [147.64954],\n        [147.54375],\n        [147.46417],\n        [147.35143],\n        [147.3332 ]], dtype=float32),\n array([[147.44226],\n        [144.86339],\n        [144.89723],\n        [144.61523],\n        [144.4813 ],\n        [144.40044],\n        [144.36198],\n        [144.35284],\n        [144.37167],\n        [144.38564],\n        [144.39778],\n        [144.37344],\n        [144.34059],\n        [144.30634],\n        [144.29367],\n        [144.2683 ],\n        [144.20973],\n        [144.17247],\n        [144.14969],\n        [144.13026],\n        [144.09926],\n        [144.09332],\n        [144.05807],\n        [144.00995],\n        [143.95364],\n        [143.91034],\n        [143.89453],\n        [143.92192],\n        [143.93237],\n        [143.93474],\n        [143.93993],\n        [143.93715],\n        [143.92601],\n        [143.93234],\n        [143.96396],\n        [144.00598],\n        [144.03902],\n        [144.05405],\n        [144.05444],\n        [144.01851],\n        [144.02737],\n        [144.0394 ],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13556],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.3635 ],\n        [147.62657],\n        [147.73491],\n        [147.75159],\n        [147.64954],\n        [147.54375],\n        [147.46417],\n        [147.35143],\n        [147.3332 ],\n        [147.39323]], dtype=float32),\n array([[147.45381],\n        [144.88658],\n        [144.90149],\n        [144.61699],\n        [144.491  ],\n        [144.41629],\n        [144.38605],\n        [144.39194],\n        [144.39821],\n        [144.40576],\n        [144.37868],\n        [144.34413],\n        [144.3088 ],\n        [144.29543],\n        [144.26952],\n        [144.21057],\n        [144.17302],\n        [144.15002],\n        [144.13046],\n        [144.09932],\n        [144.0933 ],\n        [144.05803],\n        [144.00986],\n        [143.95354],\n        [143.91023],\n        [143.89441],\n        [143.92181],\n        [143.9323 ],\n        [143.93465],\n        [143.93985],\n        [143.93709],\n        [143.92596],\n        [143.9323 ],\n        [143.96393],\n        [144.00595],\n        [144.039  ],\n        [144.05403],\n        [144.05443],\n        [144.01851],\n        [144.02736],\n        [144.03938],\n        [144.0711 ],\n        [144.1131 ],\n        [144.13554],\n        [144.163  ],\n        [144.98286],\n        [145.77818],\n        [146.4682 ],\n        [146.96971],\n        [147.36351],\n        [147.62657],\n        [147.73491],\n        [147.75159],\n        [147.64954],\n        [147.54375],\n        [147.46417],\n        [147.35143],\n        [147.3332 ],\n        [147.39323],\n        [147.51353]], dtype=float32)]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2D, but have shapes (16,) and (16, 60, 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(real_stock_price, color \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblack\u001B[39m\u001B[38;5;124m'\u001B[39m, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTATA Stock Price\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredicted_stock_price\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgreen\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mPredicted TATA Stock Price\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTATA Stock Price Prediction\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTime\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2755\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[0;32m   2756\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m   2758\u001B[0m         \u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39mscalex, scaley\u001B[38;5;241m=\u001B[39mscaley,\n\u001B[0;32m   2759\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001B[0m, in \u001B[0;36mAxes.plot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[0;32m   1392\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1629\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[0;32m   1630\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1631\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[1;32m-> 1632\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[0;32m   1633\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[0;32m   1634\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    311\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m--> 312\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\matplotlib\\axes\\_base.py:501\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[1;34m(self, tup, kwargs, return_kwargs)\u001B[0m\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must have same first dimension, but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    499\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    500\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m--> 501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y can be no greater than 2D, but have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    502\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    504\u001B[0m     x \u001B[38;5;241m=\u001B[39m x[:, np\u001B[38;5;241m.\u001B[39mnewaxis]\n",
      "\u001B[1;31mValueError\u001B[0m: x and y can be no greater than 2D, but have shapes (16,) and (16, 60, 1)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real_stock_price, color = 'black', label = 'TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'green', label = 'Predicted TATA Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lighthouseenv",
   "language": "python",
   "display_name": "LighthouseEnv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}